{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 2.2960 - acc: 0.1060\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.9757 - acc: 0.7020\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 1.5649 - acc: 0.8960\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 1s 938us/step - loss: 1.0620 - acc: 0.9860\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 1s 922us/step - loss: 0.6351 - acc: 0.9990\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 1s 891us/step - loss: 0.3567 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 1s 906us/step - loss: 0.2016 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 1s 906us/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 1s 938us/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 1s 891us/step - loss: 0.0425 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 1s 906us/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 1s 891us/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 1s 953us/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 1s 969us/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 1s 953us/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 1s 938us/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 1s 984us/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 1s 922us/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 1s 875us/step - loss: 0.0094 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x9e505ad240>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np \n",
    "\n",
    "A = pickle.load(open(\"A.pickle\", \"rb\"))\n",
    "b1 = pickle.load(open(\"b.pickle\", \"rb\"))\n",
    "b = np.asarray(b1)\n",
    "\n",
    "A = tf.keras.utils.normalize(A, axis=1) # changes data from 0-1\n",
    "\n",
    "model = tf.keras.models.Sequential() # input layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))# 128 neurons in layer\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax)) #softmax for probability distrubution\n",
    "\n",
    "\n",
    "# parameters\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "# train the model\n",
    "\n",
    "model.fit(A, b, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "IMG_SIZE = 75\n",
    "\n",
    "DATADIR = \"C:/Datasets/Circles\"\n",
    "CATEGORIES = [\"5\", \"10\", \"15\", \"20\", \"25\", \"30\", \"35\", \"40\", \"45\", \"50\"]\n",
    "\n",
    "test_data = []\n",
    "def create_test_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                test_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "create_test_data()\n",
    "\n",
    "A_test = []\n",
    "b_test = []\n",
    "\n",
    "for features, label in test_data:\n",
    "    A_test.append(features)\n",
    "    b_test.append(label)\n",
    "\n",
    "A_test = np.array(A).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "bt = np.asarray(b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 375us/step\n",
      "6.881472755432129 0.101\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(A_test, bt)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
